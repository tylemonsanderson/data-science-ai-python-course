{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46e1944",
   "metadata": {},
   "source": [
    "# Notebook 9: Scikit-Learn Basics - Your First Machine Learning Models\n",
    "\n",
    "Welcome to your ninth Python notebook! Now you'll take the next step and build your first machine learning models using scikit-learn, the most popular ML library in Python.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the machine learning workflow\n",
    "- Load and explore real datasets\n",
    "- Build classification and regression models\n",
    "- Evaluate model performance\n",
    "- Apply ML to solve real-world problems\n",
    "\n",
    "**Prerequisites:** You should have completed notebooks 1-8, especially NumPy, Pandas, and Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ce84d",
   "metadata": {},
   "source": [
    "## The Machine Learning Workflow\n",
    "\n",
    "Every ML project follows these steps:\n",
    "\n",
    "1. **Load Data** üìä\n",
    "2. **Explore & Visualize** üîç\n",
    "3. **Prepare Data** üõ†Ô∏è\n",
    "4. **Split Data** ‚úÇÔ∏è\n",
    "5. **Train Model** üß†\n",
    "6. **Evaluate Performance** üìà\n",
    "7. **Make Predictions** üéØ\n",
    "\n",
    "Let's walk through this process with real examples!\n",
    "\n",
    "## Essential Imports for Machine Learning\n",
    "\n",
    "Every ML project starts with these imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Big 4\" for machine learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.datasets import load_iris, load_boston, load_wine\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üöÄ All libraries imported successfully!\")\n",
    "print(\"Ready to build your first ML models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16259ab6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üå∏ Project 1: Iris Flower Classification\n",
    "\n",
    "Let's start with the famous Iris dataset - the \"Hello World\" of machine learning!\n",
    "\n",
    "### Step 1: Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2abfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to DataFrame for easier exploration\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"üå∏ Iris Dataset Overview:\")\n",
    "print(f\"Shape: {iris_df.shape}\")\n",
    "print(f\"Features: {list(iris.feature_names)}\")\n",
    "print(f\"Target classes: {list(iris.target_names)}\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bfdf9",
   "metadata": {},
   "source": [
    "### Step 2: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization to understand the data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Iris Dataset Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Scatter plot: Sepal length vs Sepal width\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = iris_df['species_name'] == species\n",
    "    axes[0, 0].scatter(iris_df[mask]['sepal length (cm)'], \n",
    "                      iris_df[mask]['sepal width (cm)'], \n",
    "                      label=species, alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Sepal Length (cm)')\n",
    "axes[0, 0].set_ylabel('Sepal Width (cm)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_title('Sepal Measurements')\n",
    "\n",
    "# Scatter plot: Petal length vs Petal width\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = iris_df['species_name'] == species\n",
    "    axes[0, 1].scatter(iris_df[mask]['petal length (cm)'], \n",
    "                      iris_df[mask]['petal width (cm)'], \n",
    "                      label=species, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Petal Length (cm)')\n",
    "axes[0, 1].set_ylabel('Petal Width (cm)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_title('Petal Measurements')\n",
    "\n",
    "# Distribution of species\n",
    "species_counts = iris_df['species_name'].value_counts()\n",
    "axes[1, 0].bar(species_counts.index, species_counts.values)\n",
    "axes[1, 0].set_xlabel('Species')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_title('Species Distribution')\n",
    "\n",
    "# Feature distributions\n",
    "iris_df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']].hist(ax=axes[1, 1], bins=15)\n",
    "axes[1, 1].set_title('Feature Distributions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Key Observations:\")\n",
    "print(\"- Setosa flowers have smaller petals\")\n",
    "print(\"- Virginica flowers have the largest petals\")\n",
    "print(\"- Species seem separable based on petal measurements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56092f",
   "metadata": {},
   "source": [
    "### Step 3: Prepare and Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d788da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "X = iris.data  # Features: sepal length, sepal width, petal length, petal width\n",
    "y = iris.target  # Target: species (0=setosa, 1=versicolor, 2=virginica)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Check class distribution in splits\n",
    "print(f\"\\nTraining set class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Testing set class distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832702b",
   "metadata": {},
   "source": [
    "### Step 4: Train Your First Machine Learning Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a Random Forest Classifier\n",
    "print(\"üß† Training Random Forest Classifier...\")\n",
    "\n",
    "# Create the model\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,  # Number of trees in the forest\n",
    "    random_state=42    # For reproducible results\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "print(f\"\\nüéØ Predictions made for {len(y_test)} test samples\")\n",
    "print(f\"Actual species: {y_test}\")\n",
    "print(f\"Predicted species: {y_pred}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ Model Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nüìä Detailed Performance Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb924d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è Practice Challenge: Wine Quality Prediction\n",
    "\n",
    "Now it's your turn! Try to solve this challenge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff97316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Wine Quality Prediction\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_df['wine_class'] = wine.target\n",
    "\n",
    "print(\"üç∑ Wine Dataset Challenge:\")\n",
    "print(f\"Shape: {wine_df.shape}\")\n",
    "print(f\"Classes: {wine.target_names}\")\n",
    "print(f\"Features: {len(wine.feature_names)} chemical properties\")\n",
    "\n",
    "print(\"\\nüéØ Your Challenge:\")\n",
    "print(\"1. Explore the wine dataset\")\n",
    "print(\"2. Split the data into train/test sets\")\n",
    "print(\"3. Train a classifier (try different models!)\")\n",
    "print(\"4. Evaluate performance\")\n",
    "print(\"5. Find the most important features\")\n",
    "\n",
    "# Show first few rows to get started\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb21ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine Challenge Solution\n",
    "print(\"üç∑ Wine Classification Solution:\")\n",
    "\n",
    "# Prepare the data\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "# Split the data\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(\n",
    "    X_wine, y_wine, test_size=0.2, random_state=42, stratify=y_wine\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "wine_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "wine_rf.fit(X_train_wine, y_train_wine)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_wine = wine_rf.predict(X_test_wine)\n",
    "wine_accuracy = accuracy_score(y_test_wine, y_pred_wine)\n",
    "\n",
    "print(f\"Wine Classification Accuracy: {wine_accuracy:.2%}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_wine, y_pred_wine, target_names=wine.target_names))\n",
    "\n",
    "# Feature importance\n",
    "wine_importance = wine_rf.feature_importances_\n",
    "top_features = np.argsort(wine_importance)[-5:]\n",
    "\n",
    "print(\"\\nüç∑ Top 5 Most Important Features:\")\n",
    "for i, feature_idx in enumerate(reversed(top_features)):\n",
    "    print(f\"{i+1}. {wine.feature_names[feature_idx]}: {wine_importance[feature_idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc932c10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Machine Learning Concepts You've Learned\n",
    "\n",
    "### **Classification vs Regression**\n",
    "- **Classification**: Predicting categories (Iris species, Wine types)\n",
    "- **Regression**: Predicting continuous values (house prices)\n",
    "\n",
    "### **The ML Workflow**\n",
    "1. **Data Loading**: `load_iris()`, `load_wine()`\n",
    "2. **Data Splitting**: `train_test_split()`\n",
    "3. **Model Training**: `.fit()`\n",
    "4. **Predictions**: `.predict()`\n",
    "5. **Evaluation**: `accuracy_score()`, `classification_report()`\n",
    "\n",
    "### **Model Types**\n",
    "- **Random Forest**: Combines many decision trees (usually performs well)\n",
    "- **Linear Regression**: Simple, interpretable, good baseline\n",
    "- **Logistic Regression**: Linear model for classification\n",
    "\n",
    "### **Evaluation Metrics**\n",
    "- **Classification**: Accuracy, Precision, Recall, F1-score\n",
    "- **Regression**: Mean Squared Error (MSE), R¬≤ score, RMSE\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Self-Assessment Checklist\n",
    "\n",
    "Before moving to the capstone project, make sure you can:\n",
    "\n",
    "**Machine Learning Fundamentals:**\n",
    "- [ ] Understand the difference between classification and regression\n",
    "- [ ] Follow the ML workflow: load ‚Üí explore ‚Üí split ‚Üí train ‚Üí evaluate ‚Üí predict\n",
    "- [ ] Use `train_test_split()` to create training and testing sets\n",
    "- [ ] Explain why we split data (to avoid overfitting)\n",
    "\n",
    "**Model Training:**\n",
    "- [ ] Import and use scikit-learn models\n",
    "- [ ] Train models with `.fit(X_train, y_train)`\n",
    "- [ ] Make predictions with `.predict(X_test)`\n",
    "- [ ] Get prediction probabilities with `.predict_proba()`\n",
    "\n",
    "**Model Evaluation:**\n",
    "- [ ] Calculate accuracy for classification problems\n",
    "- [ ] Interpret classification reports\n",
    "- [ ] Understand feature importance\n",
    "- [ ] Compare different models\n",
    "\n",
    "**Practical Skills:**\n",
    "- [ ] Debug common shape errors (1D vs 2D arrays)\n",
    "- [ ] Visualize model predictions vs actual values\n",
    "- [ ] Make predictions on new data\n",
    "- [ ] Apply ML to solve real-world problems\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "Congratulations! You've built your first machine learning models. In the next notebook, you'll:\n",
    "\n",
    "- **Apply everything you've learned** in a comprehensive capstone project\n",
    "- **Combine Python, NumPy, Pandas, Matplotlib, and ML** in one complete analysis\n",
    "- **Work with real-world data** and solve a practical problem\n",
    "- **Build a complete data science pipeline** from raw data to insights\n",
    "\n",
    "**Ready for the final challenge? Let's build something amazing! üéØ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ca16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boston housing dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# Convert to DataFrame\n",
    "boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "boston_df['price'] = boston.target\n",
    "\n",
    "print(\"üè† Boston Housing Dataset Overview:\")\n",
    "print(f\"Shape: {boston_df.shape}\")\n",
    "print(f\"Target: House prices (in $1000s)\")\n",
    "\n",
    "print(\"\\nDataset description:\")\n",
    "print(boston.DESCR[:500] + \"...\")\n",
    "\n",
    "# Show basic statistics\n",
    "print(\"\\nüìä Price Statistics:\")\n",
    "print(f\"Mean price: ${boston_df['price'].mean():.1f}k\")\n",
    "print(f\"Median price: ${boston_df['price'].median():.1f}k\")\n",
    "print(f\"Price range: ${boston_df['price'].min():.1f}k - ${boston_df['price'].max():.1f}k\")\n",
    "\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3f073",
   "metadata": {},
   "source": [
    "### Visualize Key Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationships between features and house prices\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('House Price Relationships', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Price distribution\n",
    "axes[0, 0].hist(boston_df['price'], bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Price ($1000s)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Price Distribution')\n",
    "\n",
    "# Number of rooms vs Price\n",
    "axes[0, 1].scatter(boston_df['RM'], boston_df['price'], alpha=0.6)\n",
    "axes[0, 1].set_xlabel('Average Number of Rooms')\n",
    "axes[0, 1].set_ylabel('Price ($1000s)')\n",
    "axes[0, 1].set_title('Rooms vs Price')\n",
    "\n",
    "# Crime rate vs Price\n",
    "axes[0, 2].scatter(boston_df['CRIM'], boston_df['price'], alpha=0.6)\n",
    "axes[0, 2].set_xlabel('Crime Rate')\n",
    "axes[0, 2].set_ylabel('Price ($1000s)')\n",
    "axes[0, 2].set_title('Crime Rate vs Price')\n",
    "\n",
    "# Distance to employment centers vs Price\n",
    "axes[1, 0].scatter(boston_df['DIS'], boston_df['price'], alpha=0.6)\n",
    "axes[1, 0].set_xlabel('Distance to Employment Centers')\n",
    "axes[1, 0].set_ylabel('Price ($1000s)')\n",
    "axes[1, 0].set_title('Distance vs Price')\n",
    "\n",
    "# Pupil-teacher ratio vs Price\n",
    "axes[1, 1].scatter(boston_df['PTRATIO'], boston_df['price'], alpha=0.6)\n",
    "axes[1, 1].set_xlabel('Pupil-Teacher Ratio')\n",
    "axes[1, 1].set_ylabel('Price ($1000s)')\n",
    "axes[1, 1].set_title('School Quality vs Price')\n",
    "\n",
    "# Correlation heatmap of top features\n",
    "correlation_features = ['price', 'RM', 'LSTAT', 'PTRATIO', 'DIS', 'CRIM']\n",
    "corr_matrix = boston_df[correlation_features].corr()\n",
    "im = axes[1, 2].imshow(corr_matrix, cmap='RdBu', vmin=-1, vmax=1)\n",
    "axes[1, 2].set_xticks(range(len(correlation_features)))\n",
    "axes[1, 2].set_yticks(range(len(correlation_features)))\n",
    "axes[1, 2].set_xticklabels(correlation_features, rotation=45)\n",
    "axes[1, 2].set_yticklabels(correlation_features)\n",
    "axes[1, 2].set_title('Feature Correlations')\n",
    "\n",
    "# Add correlation values to heatmap\n",
    "for i in range(len(correlation_features)):\n",
    "    for j in range(len(correlation_features)):\n",
    "        axes[1, 2].text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                       ha='center', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Key Insights:\")\n",
    "print(\"- More rooms = higher prices\")\n",
    "print(\"- Higher crime rate = lower prices\")\n",
    "print(\"- Better schools (lower pupil-teacher ratio) = higher prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995c3d6",
   "metadata": {},
   "source": [
    "### Train Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_boston = boston.data\n",
    "y_boston = boston.target\n",
    "\n",
    "# Split the data\n",
    "X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test_split(\n",
    "    X_boston, y_boston, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üè† Training set: {X_train_boston.shape[0]} houses\")\n",
    "print(f\"üè† Testing set: {X_test_boston.shape[0]} houses\")\n",
    "\n",
    "# Train two different models\n",
    "print(\"\\nüß† Training models...\")\n",
    "\n",
    "# 1. Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train_boston, y_train_boston)\n",
    "\n",
    "# 2. Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_boston, y_train_boston)\n",
    "\n",
    "print(\"‚úÖ Both models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe3328",
   "metadata": {},
   "source": [
    "### Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442573a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with both models\n",
    "y_pred_linear = linear_reg.predict(X_test_boston)\n",
    "y_pred_rf = rf_regressor.predict(X_test_boston)\n",
    "\n",
    "# Calculate Mean Squared Error for both models\n",
    "mse_linear = mean_squared_error(y_test_boston, y_pred_linear)\n",
    "mse_rf = mean_squared_error(y_test_boston, y_pred_rf)\n",
    "\n",
    "# Calculate R¬≤ score (coefficient of determination)\n",
    "r2_linear = linear_reg.score(X_test_boston, y_test_boston)\n",
    "r2_rf = rf_regressor.score(X_test_boston, y_test_boston)\n",
    "\n",
    "print(\"üìä Model Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Linear Regression:\")\n",
    "print(f\"  Mean Squared Error: {mse_linear:.2f}\")\n",
    "print(f\"  R¬≤ Score: {r2_linear:.3f} ({r2_linear*100:.1f}% variance explained)\")\n",
    "print(f\"  RMSE: ${np.sqrt(mse_linear):.2f}k\")\n",
    "\n",
    "print(f\"\\nRandom Forest:\")\n",
    "print(f\"  Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"  R¬≤ Score: {r2_rf:.3f} ({r2_rf*100:.1f}% variance explained)\")\n",
    "print(f\"  RMSE: ${np.sqrt(mse_rf):.2f}k\")\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Linear Regression predictions\n",
    "axes[0].scatter(y_test_boston, y_pred_linear, alpha=0.6)\n",
    "axes[0].plot([y_test_boston.min(), y_test_boston.max()], \n",
    "            [y_test_boston.min(), y_test_boston.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Price ($1000s)')\n",
    "axes[0].set_ylabel('Predicted Price ($1000s)')\n",
    "axes[0].set_title(f'Linear Regression\\nR¬≤ = {r2_linear:.3f}')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest predictions\n",
    "axes[1].scatter(y_test_boston, y_pred_rf, alpha=0.6)\n",
    "axes[1].plot([y_test_boston.min(), y_test_boston.max()], \n",
    "            [y_test_boston.min(), y_test_boston.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Price ($1000s)')\n",
    "axes[1].set_ylabel('Predicted Price ($1000s)')\n",
    "axes[1].set_title(f'Random Forest\\nR¬≤ = {r2_rf:.3f}')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "winner = \"Random Forest\" if r2_rf > r2_linear else \"Linear Regression\"\n",
    "print(f\"\\nüèÜ Winner: {winner} performs better on this dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c725080",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Machine Learning Concepts You've Learned\n",
    "\n",
    "### **Classification vs Regression**\n",
    "- **Classification**: Predicting categories (Iris species)\n",
    "- **Regression**: Predicting continuous values (house prices)\n",
    "\n",
    "### **The ML Workflow**\n",
    "1. **Data Loading**: `load_iris()`, `load_boston()`\n",
    "2. **Data Splitting**: `train_test_split()`\n",
    "3. **Model Training**: `.fit()`\n",
    "4. **Predictions**: `.predict()`\n",
    "5. **Evaluation**: `accuracy_score()`, `mean_squared_error()`\n",
    "\n",
    "### **Model Types**\n",
    "- **Random Forest**: Combines many decision trees (usually performs well)\n",
    "- **Linear Regression**: Simple, interpretable, good baseline\n",
    "- **Logistic Regression**: Linear model for classification\n",
    "\n",
    "### **Evaluation Metrics**\n",
    "- **Classification**: Accuracy, Precision, Recall, F1-score\n",
    "- **Regression**: Mean Squared Error (MSE), R¬≤ score, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d82d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è Practice Challenge: Build Your Own Model\n",
    "\n",
    "Now it's your turn! Try to solve this challenge:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296d8c7",
   "metadata": {},
   "source": [
    "### Challenge: Wine Quality Prediction\n",
    "\n",
    "Your task: Predict wine quality using the famous wine dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20a977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Wine Quality Prediction\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Load wine dataset\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_df['wine_class'] = wine.target\n",
    "wine_df['wine_name'] = wine_df['wine_class'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n",
    "\n",
    "print(\"üç∑ Wine Dataset Challenge:\")\n",
    "print(f\"Shape: {wine_df.shape}\")\n",
    "print(f\"Classes: {wine.target_names}\")\n",
    "print(f\"Features: {len(wine.feature_names)} chemical properties\")\n",
    "\n",
    "print(\"\\nüéØ Your Challenge:\")\n",
    "print(\"1. Explore the wine dataset\")\n",
    "print(\"2. Split the data into train/test sets\")\n",
    "print(\"3. Train a classifier (try different models!)\")\n",
    "print(\"4. Evaluate performance\")\n",
    "print(\"5. Find the most important features\")\n",
    "\n",
    "print(\"\\nüí™ Stretch Goals:\")\n",
    "print(\"- Compare multiple models\")\n",
    "print(\"- Create visualizations\")\n",
    "print(\"- Try feature selection\")\n",
    "\n",
    "# Show first few rows to get started\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE - Try the wine classification challenge!\n",
    "# Start by exploring the data, then build your model\n",
    "\n",
    "# Hint: You can copy and modify code from the Iris example above\n",
    "\n",
    "# Step 1: Explore the data\n",
    "# print(wine_df.describe())\n",
    "\n",
    "# Step 2: Prepare and split the data\n",
    "# X_wine = wine.data\n",
    "# y_wine = wine.target\n",
    "# X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(...)\n",
    "\n",
    "# Step 3: Train a model\n",
    "# model = RandomForestClassifier(...)\n",
    "# model.fit(...)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "# predictions = model.predict(...)\n",
    "# accuracy = accuracy_score(...)\n",
    "\n",
    "# Write your solution below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd1d97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Self-Assessment Checklist\n",
    "\n",
    "Before moving to the capstone project, make sure you can:\n",
    "\n",
    "**Machine Learning Fundamentals:**\n",
    "- [ ] Understand the difference between classification and regression\n",
    "- [ ] Follow the ML workflow: load ‚Üí explore ‚Üí split ‚Üí train ‚Üí evaluate ‚Üí predict\n",
    "- [ ] Use `train_test_split()` to create training and testing sets\n",
    "- [ ] Explain why we split data (to avoid overfitting)\n",
    "\n",
    "**Model Training:**\n",
    "- [ ] Import and use scikit-learn models\n",
    "- [ ] Train models with `.fit(X_train, y_train)`\n",
    "- [ ] Make predictions with `.predict(X_test)`\n",
    "- [ ] Get prediction probabilities with `.predict_proba()`\n",
    "\n",
    "**Model Evaluation:**\n",
    "- [ ] Calculate accuracy for classification problems\n",
    "- [ ] Calculate MSE and R¬≤ for regression problems\n",
    "- [ ] Interpret classification reports\n",
    "- [ ] Understand feature importance\n",
    "\n",
    "**Practical Skills:**\n",
    "- [ ] Debug common shape errors (1D vs 2D arrays)\n",
    "- [ ] Visualize model predictions vs actual values\n",
    "- [ ] Compare different models\n",
    "- [ ] Make predictions on new data\n",
    "\n",
    "**Data Science Connection:**\n",
    "- [ ] Recognize real-world ML applications\n",
    "- [ ] Understand when to use different models\n",
    "- [ ] Know how to interpret results for business decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d9baa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "Congratulations! You've built your first machine learning models. In the next notebook, you'll:\n",
    "\n",
    "- **Apply everything you've learned** in a comprehensive capstone project\n",
    "- **Combine Python, NumPy, Pandas, Matplotlib, and ML** in one complete analysis\n",
    "- **Work with real-world data** and solve a practical problem\n",
    "- **Build a complete data science pipeline** from raw data to insights\n",
    "\n",
    "**Ready for the final challenge? Let's build something amazing! üéØ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
